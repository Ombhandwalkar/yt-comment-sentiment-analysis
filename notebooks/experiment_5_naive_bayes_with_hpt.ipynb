{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDBw4lGrIDwz",
        "outputId": "f6c93589-98ea-4f1b-97f3-65ea962ed7d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.9 alembic-1.15.1 awscli-1.38.8 boto3-1.37.8 botocore-1.37.8 colorama-0.4.6 colorlog-6.9.0 databricks-sdk-0.45.0 docker-7.1.0 docutils-0.16 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 jmespath-1.0.1 mlflow-2.20.3 mlflow-skinny-2.20.3 optuna-4.2.1 rsa-4.7.2 s3transfer-0.11.4\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow boto3 awscli optuna imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVnvyl20IHo3",
        "outputId": "80274b04-b730-4305-ccd8-438615b7d27f"
      },
      "outputs": [],
      "source": [
        "!aws configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oDf0HOIPITDg"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "# Step 2: Set up the MLflow tracking server\n",
        "mlflow.set_tracking_uri(\"http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWZE8kOfIgqC",
        "outputId": "7d804494-5ab2-4c48-eba6-ff2aaac980dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://om-mlflow-bucket/622937322449081937', creation_time=1741368134336, experiment_id='622937322449081937', last_update_time=1741368134336, lifecycle_stage='active', name='E ML Algos with HP Tuning', tags={}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"E ML Algos with HP Tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w466F76kIivZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lHaVzFUyIkux"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/reddit_processed.csv').dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8u0kF76IqDu",
        "outputId": "b9e91f92-527f-469e-f64a-5b80fc49c85a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-07 17:41:42,864] A new study created in memory with name: no-name-2ddd1425-146a-4051-acb6-5d888ab90a31\n",
            "[I 2025-03-07 17:41:42,881] Trial 0 finished with value: 0.7096686213009682 and parameters: {'alpha': 0.030007282256800907}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:42,897] Trial 1 finished with value: 0.7089867721260057 and parameters: {'alpha': 0.022652508370870544}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:42,913] Trial 2 finished with value: 0.7078958134460658 and parameters: {'alpha': 0.000936357406166838}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:42,929] Trial 3 finished with value: 0.7080321832810582 and parameters: {'alpha': 0.008323462466573778}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:42,944] Trial 4 finished with value: 0.7083049229510432 and parameters: {'alpha': 0.1461365037183057}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:42,962] Trial 5 finished with value: 0.7083049229510432 and parameters: {'alpha': 0.11751741871586556}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:42,978] Trial 6 finished with value: 0.7077594436110732 and parameters: {'alpha': 0.303424991094032}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:43,004] Trial 7 finished with value: 0.7074867039410883 and parameters: {'alpha': 0.00025559297285672884}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:43,022] Trial 8 finished with value: 0.7077594436110732 and parameters: {'alpha': 0.006284524677703559}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:43,039] Trial 9 finished with value: 0.7081685531160508 and parameters: {'alpha': 0.010394009461385221}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:43,061] Trial 10 finished with value: 0.7076230737760807 and parameters: {'alpha': 0.0015449771878358516}. Best is trial 0 with value: 0.7096686213009682.\n",
            "[I 2025-03-07 17:41:43,086] Trial 11 finished with value: 0.7098049911359607 and parameters: {'alpha': 0.03966746004530167}. Best is trial 11 with value: 0.7098049911359607.\n",
            "[I 2025-03-07 17:41:43,110] Trial 12 finished with value: 0.7066684849311332 and parameters: {'alpha': 0.9569177728578775}. Best is trial 11 with value: 0.7098049911359607.\n",
            "[I 2025-03-07 17:41:43,130] Trial 13 finished with value: 0.7099413609709532 and parameters: {'alpha': 0.03925178435762887}. Best is trial 13 with value: 0.7099413609709532.\n",
            "[I 2025-03-07 17:41:43,151] Trial 14 finished with value: 0.7093958816309832 and parameters: {'alpha': 0.054182217181482986}. Best is trial 13 with value: 0.7099413609709532.\n",
            "[I 2025-03-07 17:41:43,172] Trial 15 finished with value: 0.7077594436110732 and parameters: {'alpha': 0.0021671470529779327}. Best is trial 13 with value: 0.7099413609709532.\n",
            "[I 2025-03-07 17:41:43,194] Trial 16 finished with value: 0.7053047865812082 and parameters: {'alpha': 0.768419388445448}. Best is trial 13 with value: 0.7099413609709532.\n",
            "[I 2025-03-07 17:41:43,215] Trial 17 finished with value: 0.7083049229510432 and parameters: {'alpha': 0.07201981093899701}. Best is trial 13 with value: 0.7099413609709532.\n",
            "[I 2025-03-07 17:41:43,235] Trial 18 finished with value: 0.7077594436110732 and parameters: {'alpha': 0.00010881532567245906}. Best is trial 13 with value: 0.7099413609709532.\n",
            "[I 2025-03-07 17:41:43,256] Trial 19 finished with value: 0.7091231419609982 and parameters: {'alpha': 0.023253359583996804}. Best is trial 13 with value: 0.7099413609709532.\n",
            "[I 2025-03-07 17:41:43,279] Trial 20 finished with value: 0.7084412927860357 and parameters: {'alpha': 0.22113311546021794}. Best is trial 13 with value: 0.7099413609709532.\n",
            "[I 2025-03-07 17:41:43,300] Trial 21 finished with value: 0.7098049911359607 and parameters: {'alpha': 0.03247664376141027}. Best is trial 13 with value: 0.7099413609709532.\n",
            "[I 2025-03-07 17:41:43,321] Trial 22 finished with value: 0.7102141006409383 and parameters: {'alpha': 0.04615149023605029}. Best is trial 22 with value: 0.7102141006409383.\n",
            "[I 2025-03-07 17:41:43,342] Trial 23 finished with value: 0.7083049229510432 and parameters: {'alpha': 0.01199344602274685}. Best is trial 22 with value: 0.7102141006409383.\n",
            "[I 2025-03-07 17:41:43,363] Trial 24 finished with value: 0.7076230737760807 and parameters: {'alpha': 0.004764756449656563}. Best is trial 22 with value: 0.7102141006409383.\n",
            "[I 2025-03-07 17:41:43,384] Trial 25 finished with value: 0.7085776626210283 and parameters: {'alpha': 0.06621234352311756}. Best is trial 22 with value: 0.7102141006409383.\n",
            "[I 2025-03-07 17:41:43,406] Trial 26 finished with value: 0.7077594436110732 and parameters: {'alpha': 0.0032143865259964444}. Best is trial 22 with value: 0.7102141006409383.\n",
            "[I 2025-03-07 17:41:43,426] Trial 27 finished with value: 0.7087140324560207 and parameters: {'alpha': 0.3538596606543139}. Best is trial 22 with value: 0.7102141006409383.\n",
            "[I 2025-03-07 17:41:43,448] Trial 28 finished with value: 0.7085776626210283 and parameters: {'alpha': 0.015397887098915047}. Best is trial 22 with value: 0.7102141006409383.\n",
            "[I 2025-03-07 17:41:43,469] Trial 29 finished with value: 0.7098049911359607 and parameters: {'alpha': 0.03343855833039357}. Best is trial 22 with value: 0.7102141006409383.\n",
            "\u001b[31m2025/03/07 17:41:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run MultinomialNB_SMOTE_TFIDF_Trigrams at: http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/#/experiments/622937322449081937/runs/3d03e5ee7fff4494a785fa27876e38d6\n",
            "🧪 View experiment at: http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/#/experiments/622937322449081937\n"
          ]
        }
      ],
      "source": [
        "# Step 1: (Optional) Remapping - skipped since not strictly needed for Multinomial Naive Bayes\n",
        "\n",
        "# Step 2: Remove rows where the target labels (category) are NaN\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "X = df['clean_comment']\n",
        "y = df['category']\n",
        "\n",
        "# Step 5: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 3: TF-IDF vectorizer setup\n",
        "ngram_range = (1, 3)  # Trigram\n",
        "max_features = 10000  # Set max_features to 1000\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train=vectorizer.fit_transform(X_train)\n",
        "X_test=vectorizer.transform(X_test)\n",
        "\n",
        "# Step 4: Apply SMOTE to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Function to log results in MLflow\n",
        "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
        "    with mlflow.start_run():\n",
        "        # Log model type\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "\n",
        "        # Log algorithm name as a parameter\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "\n",
        "\n",
        "# Step 6: Optuna objective function for Multinomial Naive Bayes\n",
        "def objective_mnb(trial):\n",
        "    alpha = trial.suggest_float('alpha', 1e-4, 1.0, log=True)  # Tuning the smoothing parameter\n",
        "\n",
        "    # MultinomialNB model setup\n",
        "    model = MultinomialNB(alpha=alpha)\n",
        "    return accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for Multinomial Naive Bayes, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_mnb, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = MultinomialNB(alpha=best_params['alpha'])\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"MultinomialNB\"\n",
        "    log_mlflow(\"MultinomialNB\", best_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Run the experiment for Multinomial Naive Bayes\n",
        "run_optuna_experiment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "887c1LqhIsKs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
