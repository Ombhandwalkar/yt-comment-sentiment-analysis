{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLmd8CRlJZur",
        "outputId": "d547c5ca-4e37-4674-ba38-d7bb703a2931"
      },
      "outputs": [],
      "source": [
        "! pip install awscli boto3 optuna imbalanced-learn mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSnvDCLNJhXZ",
        "outputId": "676b1430-45d3-45fd-beee-1bbbbb622634"
      },
      "outputs": [],
      "source": [
        "! aws configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DMhSKrOAJwYT"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "# Step 2 Set Mlflow Tracking URI\n",
        "mlflow.set_tracking_uri('http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7HyLaW9KHqt",
        "outputId": "0d0fbb9a-8d24-479a-b959-9c3f2bff7e58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://om-mlflow-bucket/622937322449081937', creation_time=1741368134336, experiment_id='622937322449081937', last_update_time=1741368134336, lifecycle_stage='active', name='E ML Algos with HP Tuning', tags={}>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set Experiment\n",
        "mlflow.set_experiment('E ML Algos with HP Tuning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wEMyz3G3KOoR"
      },
      "outputs": [],
      "source": [
        "import mlflow.sklearn\n",
        "import optuna\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cD4Y-I4K7_J",
        "outputId": "5f0ac5e5-ad5d-406f-ad9f-20480e89c5f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(36662, 2)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv('/content/reddit_processed.csv').dropna()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8qFIIwiLEXF",
        "outputId": "6aeace83-099a-403b-9636-57e3ca0df4b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-07 17:50:32,232] A new study created in memory with name: no-name-f7a62552-1904-4c68-a1cf-4f331f9c5408\n",
            "[I 2025-03-07 17:50:38,216] Trial 0 finished with value: 0.6866221191872358 and parameters: {'n_estimators': 248, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.6866221191872358.\n",
            "[I 2025-03-07 17:50:40,701] Trial 1 finished with value: 0.6783035592526933 and parameters: {'n_estimators': 131, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 19}. Best is trial 0 with value: 0.6866221191872358.\n",
            "[I 2025-03-07 17:50:44,768] Trial 2 finished with value: 0.6559389063139234 and parameters: {'n_estimators': 244, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.6866221191872358.\n",
            "[I 2025-03-07 17:50:45,681] Trial 3 finished with value: 0.6252556934406109 and parameters: {'n_estimators': 51, 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.6866221191872358.\n",
            "[I 2025-03-07 17:50:49,282] Trial 4 finished with value: 0.6444838401745534 and parameters: {'n_estimators': 180, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.6866221191872358.\n",
            "[I 2025-03-07 17:50:51,283] Trial 5 finished with value: 0.6271648711305059 and parameters: {'n_estimators': 194, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.6866221191872358.\n",
            "[I 2025-03-07 17:50:54,129] Trial 6 finished with value: 0.6519841810991409 and parameters: {'n_estimators': 207, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 20}. Best is trial 0 with value: 0.6866221191872358.\n",
            "[I 2025-03-07 17:50:55,758] Trial 7 finished with value: 0.6731215055229783 and parameters: {'n_estimators': 70, 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.6866221191872358.\n",
            "[I 2025-03-07 17:50:58,320] Trial 8 finished with value: 0.6388926769398608 and parameters: {'n_estimators': 210, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.6866221191872358.\n",
            "[I 2025-03-07 17:50:59,959] Trial 9 finished with value: 0.636165280240011 and parameters: {'n_estimators': 99, 'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.6866221191872358.\n",
            "[I 2025-03-07 17:51:12,433] Trial 10 finished with value: 0.6994408836765308 and parameters: {'n_estimators': 296, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.6994408836765308.\n",
            "[I 2025-03-07 17:51:25,091] Trial 11 finished with value: 0.6990317741715533 and parameters: {'n_estimators': 297, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.6994408836765308.\n",
            "[I 2025-03-07 17:51:37,847] Trial 12 finished with value: 0.7002591026864857 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:51:49,501] Trial 13 finished with value: 0.6984862948315832 and parameters: {'n_estimators': 284, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:51:56,075] Trial 14 finished with value: 0.6759852720578208 and parameters: {'n_estimators': 260, 'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:52:02,525] Trial 15 finished with value: 0.6740760943679258 and parameters: {'n_estimators': 298, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:52:07,830] Trial 16 finished with value: 0.6927587617618983 and parameters: {'n_estimators': 145, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:52:14,925] Trial 17 finished with value: 0.6883949270421382 and parameters: {'n_estimators': 266, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:52:20,875] Trial 18 finished with value: 0.6652120550934133 and parameters: {'n_estimators': 233, 'max_depth': 12, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:52:30,458] Trial 19 finished with value: 0.6956225282967408 and parameters: {'n_estimators': 274, 'max_depth': 18, 'min_samples_split': 13, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:52:35,524] Trial 20 finished with value: 0.6908495840720033 and parameters: {'n_estimators': 225, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:52:48,098] Trial 21 finished with value: 0.6999863630165007 and parameters: {'n_estimators': 298, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:52:57,100] Trial 22 finished with value: 0.6958952679667257 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:53:05,359] Trial 23 finished with value: 0.6941224601118232 and parameters: {'n_estimators': 274, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:53:13,620] Trial 24 finished with value: 0.6905768444020183 and parameters: {'n_estimators': 255, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:53:22,489] Trial 25 finished with value: 0.6926223919269058 and parameters: {'n_estimators': 285, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:53:26,661] Trial 26 finished with value: 0.6838947224873858 and parameters: {'n_estimators': 155, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:53:32,898] Trial 27 finished with value: 0.6896222555570708 and parameters: {'n_estimators': 233, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:53:40,642] Trial 28 finished with value: 0.6898949952270558 and parameters: {'n_estimators': 267, 'max_depth': 17, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.7002591026864857.\n",
            "[I 2025-03-07 17:53:47,097] Trial 29 finished with value: 0.6948043092867857 and parameters: {'n_estimators': 250, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 11}. Best is trial 12 with value: 0.7002591026864857.\n",
            "\u001b[31m2025/03/07 17:54:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run RandomForest_SMOTE_TFIDF_Trigrams at: http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/#/experiments/622937322449081937/runs/3c092b6a9de044aea5101b32b3ef770c\n",
            "üß™ View experiment at: http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/#/experiments/622937322449081937\n"
          ]
        }
      ],
      "source": [
        "# Step 1: (Optional) Remapping - skipped since not strictly needed for Random Forest\n",
        "\n",
        "# Step 2: Remove rows where the target labels (category) are NaN\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "X = df['clean_comment']\n",
        "y = df['category']\n",
        "\n",
        "# Step 5: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 3: TF-IDF vectorizer setup\n",
        "ngram_range = (1, 3)  # Trigram\n",
        "max_features = 10000  # Set max_features to 1000\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train=vectorizer.fit_transform(X_train)\n",
        "X_test=vectorizer.transform(X_test)\n",
        "\n",
        "# Step 4: Apply SMOTE to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Function to log results in MLflow\n",
        "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
        "    with mlflow.start_run():\n",
        "        # Log model type\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "\n",
        "        # Log algorithm name as a parameter\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "\n",
        "\n",
        "# Step 6: Optuna objective function for Random Forest\n",
        "def objective_rf(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)  # Number of trees in the forest\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 20)  # Maximum depth of the tree\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)  # Minimum samples required to split a node\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)  # Minimum samples required at a leaf node\n",
        "\n",
        "    # RandomForestClassifier setup\n",
        "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
        "                                   min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
        "                                   random_state=42)\n",
        "    return accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for Random Forest, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_rf, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
        "                                        max_depth=best_params['max_depth'],\n",
        "                                        min_samples_split=best_params['min_samples_split'],\n",
        "                                        min_samples_leaf=best_params['min_samples_leaf'],\n",
        "                                        random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"RandomForest\"\n",
        "    log_mlflow(\"RandomForest\", best_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Run the experiment for Random Forest\n",
        "run_optuna_experiment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEXJEWkxRrP4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
