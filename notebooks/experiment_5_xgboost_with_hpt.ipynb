{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3432AKKcSaB",
        "outputId": "55fcc5ae-e084-4335-8c98-ba13a375d713"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow boto3 awscli optuna xgboost imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxzL1KMQcm8v",
        "outputId": "fd67e963-fb41-43aa-d3bf-63009e11d6bd"
      },
      "outputs": [],
      "source": [
        "! aws configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fJ2zxtQwdKpu"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "# Step 2: Set up the MLflow tracking server\n",
        "mlflow.set_tracking_uri(\"http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mCi3xM_dhuW",
        "outputId": "22400477-a852-42e6-b2ff-79f6a4eca673"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://om-mlflow-bucket/622937322449081937', creation_time=1741368134336, experiment_id='622937322449081937', last_update_time=1741368134336, lifecycle_stage='active', name='E ML Algos with HP Tuning', tags={}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"E ML Algos with HP Tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dMOXjycEdqgF"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gqJ2TdDudsX5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/reddit_processed.csv').dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUPdTqVDdyIQ",
        "outputId": "27aa32df-1d94-410f-def6-4c1d83775e75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-08 03:04:32,357] A new study created in memory with name: no-name-43be1124-cf6e-4aa7-9ddb-705e788dd7b4\n",
            "[I 2025-03-08 03:04:45,085] Trial 0 finished with value: 0.8006334682386064 and parameters: {'n_estimators': 85, 'learning_rate': 0.0630929730109592, 'max_depth': 4}. Best is trial 0 with value: 0.8006334682386064.\n",
            "[I 2025-03-08 03:06:56,514] Trial 1 finished with value: 0.7096603906387472 and parameters: {'n_estimators': 242, 'learning_rate': 0.00013285313296061823, 'max_depth': 9}. Best is trial 0 with value: 0.8006334682386064.\n",
            "[I 2025-03-08 03:07:21,347] Trial 2 finished with value: 0.6873130388879113 and parameters: {'n_estimators': 77, 'learning_rate': 0.0018899862204812589, 'max_depth': 6}. Best is trial 0 with value: 0.8006334682386064.\n",
            "[I 2025-03-08 03:09:41,466] Trial 3 finished with value: 0.7094844272391343 and parameters: {'n_estimators': 215, 'learning_rate': 0.00022099903246740953, 'max_depth': 10}. Best is trial 0 with value: 0.8006334682386064.\n",
            "[I 2025-03-08 03:10:27,545] Trial 4 finished with value: 0.8301953193735703 and parameters: {'n_estimators': 113, 'learning_rate': 0.042435073648163034, 'max_depth': 8}. Best is trial 4 with value: 0.8301953193735703.\n",
            "[I 2025-03-08 03:10:37,876] Trial 5 finished with value: 0.6718282597219778 and parameters: {'n_estimators': 106, 'learning_rate': 0.008688188843277829, 'max_depth': 3}. Best is trial 4 with value: 0.8301953193735703.\n",
            "[I 2025-03-08 03:11:04,727] Trial 6 finished with value: 0.6507126517684322 and parameters: {'n_estimators': 154, 'learning_rate': 0.0007155943462036732, 'max_depth': 4}. Best is trial 4 with value: 0.8301953193735703.\n",
            "[I 2025-03-08 03:11:37,741] Trial 7 finished with value: 0.7105402076368116 and parameters: {'n_estimators': 70, 'learning_rate': 0.0004938181551961158, 'max_depth': 8}. Best is trial 4 with value: 0.8301953193735703.\n",
            "[I 2025-03-08 03:12:34,257] Trial 8 finished with value: 0.8036248460320253 and parameters: {'n_estimators': 200, 'learning_rate': 0.02008348508863395, 'max_depth': 6}. Best is trial 4 with value: 0.8301953193735703.\n",
            "[I 2025-03-08 03:12:47,686] Trial 9 finished with value: 0.6227344712299842 and parameters: {'n_estimators': 122, 'learning_rate': 0.0014039926697836762, 'max_depth': 3}. Best is trial 4 with value: 0.8301953193735703.\n",
            "[I 2025-03-08 03:13:55,674] Trial 10 finished with value: 0.9046278374098188 and parameters: {'n_estimators': 280, 'learning_rate': 0.09072364610174397, 'max_depth': 8}. Best is trial 10 with value: 0.9046278374098188.\n",
            "[I 2025-03-08 03:15:00,770] Trial 11 finished with value: 0.9090269224001408 and parameters: {'n_estimators': 291, 'learning_rate': 0.09810602745973496, 'max_depth': 8}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:16:00,544] Trial 12 finished with value: 0.9035720570121415 and parameters: {'n_estimators': 287, 'learning_rate': 0.09223526182556693, 'max_depth': 7}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:19:17,633] Trial 13 finished with value: 0.8004575048389935 and parameters: {'n_estimators': 296, 'learning_rate': 0.006906503417998222, 'max_depth': 10}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:21:01,343] Trial 14 finished with value: 0.8356501847615696 and parameters: {'n_estimators': 257, 'learning_rate': 0.019922203538572478, 'max_depth': 8}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:22:16,367] Trial 15 finished with value: 0.8514868907267289 and parameters: {'n_estimators': 264, 'learning_rate': 0.031755912824030647, 'max_depth': 7}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:23:20,515] Trial 16 finished with value: 0.9067393982051734 and parameters: {'n_estimators': 235, 'learning_rate': 0.0983022193973689, 'max_depth': 9}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:25:41,251] Trial 17 finished with value: 0.786556396269576 and parameters: {'n_estimators': 226, 'learning_rate': 0.006884947790176421, 'max_depth': 9}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:27:20,058] Trial 18 finished with value: 0.8022171388351222 and parameters: {'n_estimators': 178, 'learning_rate': 0.014873371414615328, 'max_depth': 9}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:28:06,361] Trial 19 finished with value: 0.8351222945627309 and parameters: {'n_estimators': 241, 'learning_rate': 0.034582039567787416, 'max_depth': 5}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:29:24,009] Trial 20 finished with value: 0.8791131444659511 and parameters: {'n_estimators': 193, 'learning_rate': 0.0537018579395491, 'max_depth': 10}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:30:30,012] Trial 21 finished with value: 0.9067393982051734 and parameters: {'n_estimators': 281, 'learning_rate': 0.09495217754672705, 'max_depth': 8}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:31:30,948] Trial 22 finished with value: 0.9005806792187225 and parameters: {'n_estimators': 300, 'learning_rate': 0.08442818586650341, 'max_depth': 7}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:33:11,110] Trial 23 finished with value: 0.8682034136899525 and parameters: {'n_estimators': 271, 'learning_rate': 0.033499472374985934, 'max_depth': 9}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:35:20,300] Trial 24 finished with value: 0.7654407883160302 and parameters: {'n_estimators': 244, 'learning_rate': 0.0033925100024219646, 'max_depth': 8}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:36:42,777] Trial 25 finished with value: 0.8882632412458209 and parameters: {'n_estimators': 261, 'learning_rate': 0.05651328999315073, 'max_depth': 9}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:38:06,246] Trial 26 finished with value: 0.796762273447123 and parameters: {'n_estimators': 219, 'learning_rate': 0.012719440414566208, 'max_depth': 7}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:38:49,571] Trial 27 finished with value: 0.8045046630300897 and parameters: {'n_estimators': 155, 'learning_rate': 0.02652844081366966, 'max_depth': 6}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:39:57,155] Trial 28 finished with value: 0.907091325004399 and parameters: {'n_estimators': 282, 'learning_rate': 0.09852910386497099, 'max_depth': 8}. Best is trial 11 with value: 0.9090269224001408.\n",
            "[I 2025-03-08 03:41:30,045] Trial 29 finished with value: 0.8903748020411755 and parameters: {'n_estimators': 252, 'learning_rate': 0.054043431760617704, 'max_depth': 10}. Best is trial 11 with value: 0.9090269224001408.\n",
            "\u001b[31m2025/03/08 03:42:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run XGBoost_SMOTE_TFIDF_Trigrams at: http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/#/experiments/622937322449081937/runs/b001749aea4545e3987cc31c943b1553\n",
            "🧪 View experiment at: http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/#/experiments/622937322449081937\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
        "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "\n",
        "# Step 2: Remove rows where the target labels (category) are NaN\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "ngram_range = (1, 3)  # Trigram setting\n",
        "max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
        "\n",
        "# Step 4: Train-test split before vectorization and resampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
        "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
        "\n",
        "# Function to log results in MLflow\n",
        "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
        "    with mlflow.start_run():\n",
        "        # Log model type\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "\n",
        "        # Log algorithm name as a parameter\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "\n",
        "\n",
        "# Step 6: Optuna objective function for XGBoost\n",
        "def objective_xgboost(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "\n",
        "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
        "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for XGBoost, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_xgboost, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
        "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
        "\n",
        "# Run the experiment for XGBoost\n",
        "run_optuna_experiment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-YHeV8yd0jG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
