{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JxnDGi7GIdC",
        "outputId": "81a45d92-9884-4b68-92ff-a37abe96990e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.9 alembic-1.15.1 awscli-1.38.8 boto3-1.37.8 botocore-1.37.8 colorama-0.4.6 colorlog-6.9.0 databricks-sdk-0.45.0 docker-7.1.0 docutils-0.16 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 jmespath-1.0.1 mlflow-2.20.3 mlflow-skinny-2.20.3 optuna-4.2.1 rsa-4.7.2 s3transfer-0.11.4\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow boto3 awscli optuna imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1gbN9fOGKxv",
        "outputId": "13037b91-00bd-4b7e-9335-bc3d7d07c287"
      },
      "outputs": [],
      "source": [
        "!aws configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ixboe2hPGtue"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "# Step 2: Set up the MLflow tracking server\n",
        "mlflow.set_tracking_uri(\"http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvIFggI4G63B",
        "outputId": "eaa410d7-2eb9-4caf-b1bf-eea7ce89bc39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://om-mlflow-bucket/622937322449081937', creation_time=1741368134336, experiment_id='622937322449081937', last_update_time=1741368134336, lifecycle_stage='active', name='E ML Algos with HP Tuning', tags={}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"E ML Algos with HP Tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L2g4MpecG-HL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dRLGF7LnHAQC"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/reddit_processed.csv').dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6WNoSp4HFI-",
        "outputId": "617ca659-3582-4c55-b0fa-879a91dfd0e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-07 18:05:33,825] A new study created in memory with name: no-name-095a4039-2fe8-4799-b787-068521f3d9bf\n",
            "[I 2025-03-07 18:05:33,928] Trial 0 finished with value: 0.3448793126960316 and parameters: {'C': 0.0063253301841741955, 'penalty': 'l1'}. Best is trial 0 with value: 0.3448793126960316.\n",
            "[I 2025-03-07 18:05:34,547] Trial 1 finished with value: 0.7204418382653757 and parameters: {'C': 0.03762173843991048, 'penalty': 'l2'}. Best is trial 1 with value: 0.7204418382653757.\n",
            "[I 2025-03-07 18:05:34,766] Trial 2 finished with value: 0.626073912450566 and parameters: {'C': 0.029391439166800697, 'penalty': 'l1'}. Best is trial 1 with value: 0.7204418382653757.\n",
            "[I 2025-03-07 18:05:34,861] Trial 3 finished with value: 0.3448793126960316 and parameters: {'C': 0.002787312880154015, 'penalty': 'l1'}. Best is trial 1 with value: 0.7204418382653757.\n",
            "[I 2025-03-07 18:05:35,533] Trial 4 finished with value: 0.8354016091640529 and parameters: {'C': 4.805310346248202, 'penalty': 'l2'}. Best is trial 4 with value: 0.8354016091640529.\n",
            "[I 2025-03-07 18:05:35,654] Trial 5 finished with value: 0.6717578071730533 and parameters: {'C': 0.0012708048243753962, 'penalty': 'l2'}. Best is trial 4 with value: 0.8354016091640529.\n",
            "[I 2025-03-07 18:05:36,201] Trial 6 finished with value: 0.8607663984726579 and parameters: {'C': 5.608954381290687, 'penalty': 'l1'}. Best is trial 6 with value: 0.8607663984726579.\n",
            "[I 2025-03-07 18:05:36,317] Trial 7 finished with value: 0.6331651438701759 and parameters: {'C': 0.032063653042165345, 'penalty': 'l1'}. Best is trial 6 with value: 0.8607663984726579.\n",
            "[I 2025-03-07 18:05:36,469] Trial 8 finished with value: 0.7550797763534706 and parameters: {'C': 0.12375187421621812, 'penalty': 'l1'}. Best is trial 6 with value: 0.8607663984726579.\n",
            "[I 2025-03-07 18:05:36,740] Trial 9 finished with value: 0.8789035865266603 and parameters: {'C': 1.6567371497075638, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:37,130] Trial 10 finished with value: 0.8049911359607255 and parameters: {'C': 0.4718591080222135, 'penalty': 'l2'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:37,762] Trial 11 finished with value: 0.8484931133233329 and parameters: {'C': 8.469559983295982, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:38,036] Trial 12 finished with value: 0.8739942724669303 and parameters: {'C': 1.1081853362331142, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:38,303] Trial 13 finished with value: 0.8692213282421928 and parameters: {'C': 0.8675582270375917, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:38,569] Trial 14 finished with value: 0.8734487931269603 and parameters: {'C': 1.077569530828317, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:38,745] Trial 15 finished with value: 0.805945724805673 and parameters: {'C': 0.24662859184833108, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:38,809] Trial 16 finished with value: 0.3448793126960316 and parameters: {'C': 0.00025930909700672735, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:39,118] Trial 17 finished with value: 0.8779489976817128 and parameters: {'C': 1.8684783835153091, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:39,702] Trial 18 finished with value: 0.8292649665893904 and parameters: {'C': 2.122838027346661, 'penalty': 'l2'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:39,923] Trial 19 finished with value: 0.7808536751670531 and parameters: {'C': 0.17303126820176007, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:40,271] Trial 20 finished with value: 0.8786308468566753 and parameters: {'C': 2.1000837284377227, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:40,644] Trial 21 finished with value: 0.8752216009818629 and parameters: {'C': 2.560893669401252, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:40,860] Trial 22 finished with value: 0.8389472248738579 and parameters: {'C': 0.43039230195182887, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:41,235] Trial 23 finished with value: 0.8754943406518478 and parameters: {'C': 2.5382858618177955, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:41,397] Trial 24 finished with value: 0.7145779353606982 and parameters: {'C': 0.07879407479681819, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:41,609] Trial 25 finished with value: 0.8469930451384153 and parameters: {'C': 0.48950033131842347, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:42,424] Trial 26 finished with value: 0.8328105822991955 and parameters: {'C': 8.879450719107988, 'penalty': 'l2'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:42,774] Trial 27 finished with value: 0.8779489976817128 and parameters: {'C': 2.213607230931622, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:42,868] Trial 28 finished with value: 0.4351561434610664 and parameters: {'C': 0.010403342110359417, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "[I 2025-03-07 18:05:43,132] Trial 29 finished with value: 0.8748124914768853 and parameters: {'C': 1.2803809619759052, 'penalty': 'l1'}. Best is trial 9 with value: 0.8789035865266603.\n",
            "\u001b[31m2025/03/07 18:05:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run LogisticRegression_SMOTE_TFIDF_Trigrams at: http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/#/experiments/622937322449081937/runs/9afab219de76450890dd366c599ecaa1\n",
            "🧪 View experiment at: http://ec2-100-26-36-125.compute-1.amazonaws.com:5000/#/experiments/622937322449081937\n"
          ]
        }
      ],
      "source": [
        "# Step 1: (Optional) Remapping - skipped since not strictly needed for Logistic Regression\n",
        "\n",
        "# Step 2: Remove rows where the target labels (category) are NaN\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "X = df['clean_comment']\n",
        "y = df['category']\n",
        "\n",
        "\n",
        "\n",
        "# Step 5: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "# Step 3: TF-IDF vectorizer setup\n",
        "ngram_range = (1, 3)  # Trigram\n",
        "max_features = 10000  # Set max_features to 1000\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train=vectorizer.fit_transform(X_train)\n",
        "X_test=vectorizer.transform(X_test)\n",
        "\n",
        "# Step 4: Apply SMOTE to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Function to log results in MLflow\n",
        "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
        "    with mlflow.start_run():\n",
        "        # Log model type\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "\n",
        "        # Log algorithm name as a parameter\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "\n",
        "\n",
        "# Step 6: Optuna objective function for Logistic Regression\n",
        "def objective_logreg(trial):\n",
        "    C = trial.suggest_float('C', 1e-4, 10.0, log=True)\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "\n",
        "    # LogisticRegression model setup with balanced class weight\n",
        "    model = LogisticRegression(C=C, penalty=penalty, solver='liblinear', random_state=42)\n",
        "    return accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for Logistic Regression, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_logreg, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'], solver='liblinear', random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"LogisticRegression\"\n",
        "    log_mlflow(\"LogisticRegression\", best_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Run the experiment for Logistic Regression\n",
        "run_optuna_experiment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V53XDDScHH45"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
